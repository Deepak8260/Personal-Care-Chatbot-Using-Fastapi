# ğŸ’¬ Personal Care Product Chatbot (FastAPI + Gemini + LangChain + Supabase)

An intelligent AI-based chatbot that helps users get product information, benefits, and support details for **personal care products** through natural conversations.

This project integrates **FastAPI**, **LangChain agents**, **Google Gemini**, **SQLAlchemy**, and **Supabase (PostgreSQL)** into one seamless pipeline â€” converting plain English questions into SQL queries, fetching structured data, and returning well-formatted AI responses.

---



| **Platform**  | **Description**                                                                                   | **Live URL**                                                                                                |
| ------------- | ------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| **Render**    | Complete deployment of the full application (both FastAPI backend and LangChain-powered logic).   | ğŸ”— [https://personal-care-chatbot-fastapi.onrender.com](https://personal-care-chatbot-using-fastapi.onrender.com/) |
| **Streamlit** | Full app deployment with integrated backend and chat UI, accessible directly via Streamlit Cloud. | ğŸ’¬ [https://personal-care-chatbot.streamlit.app](https://personal-care-chatbot-new.streamlit.app/)               |




## ğŸš€ Core Tech Stack

| Category           | Tool / Library                                      | Purpose                                                |
| ------------------ | --------------------------------------------------- | ------------------------------------------------------ |
| ğŸ§  LLM             | **Gemini 2.5 Flash** (via `langchain-google-genai`) | Natural language understanding and response generation |
| ğŸ”— Agent Framework | **LangChain**                                       | Orchestrates the logic between LLM, SQL, and reasoning |
| ğŸ—ƒï¸ Database ORM   | **SQLAlchemy**                                      | Executes SQL queries, manages chat history             |
| â˜ï¸ Cloud DB        | **Supabase (PostgreSQL)**                           | Stores product details & chat history                  |
| âš™ï¸ Backend         | **FastAPI**                                         | Handles API endpoints, connects frontend and backend   |
| ğŸ–¥ï¸ Frontend       | **HTML, CSS, JS**                                   | Chat interface for user interaction                    |
| ğŸ” Config          | **dotenv**                                          | Stores API keys and database credentials securely      |
| ğŸ³ Deployment      | **Docker**                                          | Containerizes the whole app for easy deployment        |

---

## ğŸ§© Folder Structure

```
personal-care-chatbot/
â”‚
â”œâ”€â”€ app.py                     # FastAPI main app (entry point)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py            # Loads API keys and database URL
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ llm_service.py         # Initializes Gemini LLM
â”‚   â”œâ”€â”€ db_service.py          # Connects to Supabase DB using SQLAlchemy
â”‚   â”œâ”€â”€ agent_service.py       # Defines LangChain SQL Agent
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html             # Chatbot UI
â”‚   â”œâ”€â”€ style.css              # Modern UI design (glass effect)
â”‚   â””â”€â”€ script.js              # Handles message sending
â”‚
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .env                       # API keys & DB credentials
â””â”€â”€ Dockerfile                 # For container deployment
```

---

## ğŸ§  Complete Workflow â€” Step-by-Step (Behind the Scenes)

Hereâ€™s how **each component interacts** when a user asks a question:

---

### ğŸ§© Step 1 â€” User Sends a Query (Frontend)

* The user types a message in `index.html`.
* `script.js` captures it and sends it to the backend endpoint:

  ```http
  POST /ask
  {
    "user_query": "What is the price of Dove soap?"
  }
  ```

---

### âš™ï¸ Step 2 â€” FastAPI Receives Request (`app.py`)

FastAPI (in `app.py`) does the following:

1. **Fetches last 5 chats** from Supabase using:

   ```python
   from services.db_service import fetch_last_5_chats
   ```

   These chats give *context* for a more natural conversation.

2. **Combines** the userâ€™s query with the last 5 messages â†’ builds a **contextual prompt**.

3. Sends this to the **LangChain SQL Agent** for intelligent query processing.

---

### ğŸ¤– Step 3 â€” LangChain SQL Agent (`agent_service.py`)

The **LangChain Agent** acts as the **central brain**.

It receives the contextual prompt and decides:

* If the query is about **structured data** (price, availability, category):
  â†’ it **creates an SQL query** using LangChainâ€™s `create_sql_agent()`.

* If the query is **descriptive** (e.g., â€œIs Dove soap good for dry skin?â€):
  â†’ it switches to **reasoning mode**, skipping SQL and using **Geminiâ€™s internal knowledge**.

* If the query involves **returns, defects, or complaints**:
  â†’ it immediately responds with:

  ```
  "Final Answer: For immediate assistance with defective products or returns, please call +91-9999333943."
  ```

The logic and behavior of the agent are defined in a **custom system prompt** inside `agent_service.py`.

---

### ğŸ§® Step 4 â€” SQLAlchemy Executes the Query (`db_service.py`)

If the agent decides to query the database:

1. The agent uses the **LangChain SQL Toolkit** which internally uses **SQLAlchemy** to connect to the Supabase DB.

2. SQLAlchemy (through the connection string in `.env`) executes the generated SQL query:

   ```python
   engine = create_engine(SUPABASE_DB_URL)
   db = SQLDatabase(engine=engine)
   ```

3. The query results (product details, price, etc.) are returned back to the agent.

---

### ğŸ§  Step 5 â€” Gemini Refines the Response (`llm_service.py`)

After getting the raw response (either from SQL or reasoning), it is passed again to **Gemini** using:

```python
cleaned_output = llm.invoke(full_prompt).content
```

Here Gemini acts as a **refiner and rewriter** â€” it:

* Removes technical tags or artifacts.
* Expands the answer into **natural, human-like text**.
* Makes the reply conversational and polished.

---

### ğŸ’¾ Step 6 â€” Chat History Storage (`db_service.py`)

The final response (both question and answer) is stored into the `chat_history` table using:

```python
store_chat(user_message, cleaned_output)
```

This enables context-based conversations (last 5 messages are reused each time).

---

### ğŸ’¬ Step 7 â€” Response Sent to Frontend

Finally, FastAPI returns:

```json
{
  "user_query": "What is the price of Dove soap?",
  "response": "The price of Dove Soap is â‚¹299 for 100g.",
  "status": "âœ… saved to chat_history"
}
```

And the frontend (`script.js`) displays it beautifully in the chat UI.

---

## ğŸ§± Component Contributions Summary

| Component             | Technology Used             | Role                                          |
| --------------------- | --------------------------- | --------------------------------------------- |
| **Frontend**          | HTML, CSS, JS               | User interaction, sending/receiving messages  |
| **Backend Framework** | FastAPI                     | API handling, connects all services           |
| **AI Model**          | Gemini 2.5 Flash            | Natural language understanding and generation |
| **LangChain**         | `create_sql_agent()`        | Converts user query â†’ SQL â†’ response          |
| **Database Layer**    | SQLAlchemy + Supabase       | Executes SQL and stores chat logs             |
| **Memory**            | Custom (chat_history table) | Contextual continuity across messages         |
| **Containerization**  | Docker                      | Portable and consistent deployment            |

---

## ğŸ§¾ Example Conversation Flow

| Step | Component       | Example Action                                                                              |
| ---- | --------------- | ------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£  | Frontend        | User types â€œShow me all shampoos under â‚¹500.â€                                               |
| 2ï¸âƒ£  | FastAPI         | Passes query to LangChain Agent                                                             |
| 3ï¸âƒ£  | LangChain Agent | Converts to SQL â†’ `SELECT * FROM product_details WHERE category='shampoo' AND price < 500;` |
| 4ï¸âƒ£  | SQLAlchemy      | Executes SQL on Supabase                                                                    |
| 5ï¸âƒ£  | Supabase        | Returns matching product records                                                            |
| 6ï¸âƒ£  | Gemini          | Formats into: â€œHere are some shampoos under â‚¹500...â€                                        |
| 7ï¸âƒ£  | FastAPI         | Stores chat and sends response to frontend                                                  |
| 8ï¸âƒ£  | Frontend        | Displays the AI response beautifully in the UI                                              |

---

## ğŸ§  System Architecture Diagram (Text-Based)

```
User â”€â”€â–¶ Frontend (HTML/JS)
          â”‚
          â–¼
      FastAPI (app.py)
          â”‚
          â–¼
   LangChain Agent (Textâ†’SQL)
          â”‚
      â”Œâ”€â”€â”€â”´â”€â”€â”€â”
      â–¼       â–¼
  SQLAlchemy   Gemini LLM
   (Executes)  (Refines)
      â”‚            â”‚
      â–¼            â–¼
  Supabase DB   Final Response
      â”‚            â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â–¶ Chat History
                   â”‚
                   â–¼
               Frontend UI
```

---

## ğŸ§° How to Run the Project Locally

```bash
# Clone
git clone https://github.com/yourusername/personal-care-chatbot.git
cd personal-care-chatbot

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

# Add credentials
echo "GEMINI_API_KEY=your_api_key" >> .env
echo "SUPABASE_DB_URL=your_supabase_url" >> .env

# Run the app
uvicorn app:app --reload
```

Visit ğŸ‘‰ **[http://127.0.0.1:8000](http://127.0.0.1:8000)**

---

## ğŸ³ Running with Docker

You donâ€™t need to build the image manually â€” itâ€™s already available on **Docker Hub**.
Simply **pull** and **run** it using the following commands ğŸ‘‡

### ğŸ§¾ Step 1 â€” Pull the Image

```bash
docker pull kumar3472/personal-care-fastapi:latest
```

### ğŸ§¾ Step 2 â€” Run the Container

Youâ€™ll need to provide your credentials via the `--env` or `--env-file` option so that the container can access the Gemini API and Supabase database.

#### Option 1 â€” Using `.env` file

(Recommended if you already have a `.env` file in the same directory)

```bash
docker run -d -p 8000:8000 --env-file .env kumar3472/personal-care-fastapi:latest
```

#### Option 2 â€” Passing Environment Variables Directly

```bash
docker run -d -p 8000:8000 \
  -e GEMINI_API_KEY=your_api_key \
  -e SUPABASE_DB_URL=your_supabase_database_url \
  kumar3472/personal-care-fastapi:latest
```

Now open your browser at ğŸ‘‰ **[http://localhost:8000](http://localhost:8000)**
Your chatbot will be live and ready to use! ğŸš€

---

## ğŸ” Example Queries

| Type            | Example Query                              | Agent Behavior                    |
| --------------- | ------------------------------------------ | --------------------------------- |
| ğŸ’° Price Query  | â€œWhatâ€™s the price of Lâ€™Oreal conditioner?â€ | Converts to SQL + fetches from DB |
| ğŸ’¡ General Info | â€œIs Dove good for oily skin?â€              | Uses reasoning via Gemini         |
| ğŸ“ Support      | â€œMy product is defectiveâ€                  | Triggers support message          |

---

## ğŸ§‘â€ğŸ’» Author

**ğŸ‘¤ Deepak Kumar Mohanty**
ğŸ“ BCA Graduate | ğŸ’» Data Scientist & Python Developer
ğŸ“ Balasore, Odisha, India
---
